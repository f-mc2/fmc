---
dg-home: false
dg-publish: true
---

# 1 Limits of scalar functions



1) Compute
   $$
   \lim_{x\rightarrow x_{0}} f(x)= f(x_{0})
   $$
   for $f(x)=c$, $f(x)=x$, and $f(x)=x^{2}$.  
   
>[!note]- Solution
>Let us start considering the constant function $f(x)=c$ with $x\in\mathbb{R}$, and prove that
>$$
>\lim_{x\rightarrow x_{0}} f(x)= f(x_{0}).
>$$
>Indeed, it immediately follows that $|f(x) - f(x_{0})|=0<\epsilon$ for every $x\in\mathbb{R}$ and every $\epsilon>0$.
>Now, let us consider the function $f(x)=x$, and prove that
>$$ 
>\lim_{x\rightarrow x_{0}} f(x)= f(x_{0}). 
>$$
>Again, it is immediate to check that $|f(x) - f(x_{0})|=|x - x_{0}|$, and thus, taking $\delta_{\epsilon}< \epsilon$, we get that $|x - x_{0}|<\delta_{\epsilon}$ implies $|f(x) - f(x_{0})|<\epsilon$. 
	> Finally, let us consider the function $f(x)=x^{2}$, and prove that 
	> $$ \lim_{x\rightarrow x_{0}} f(x)= f(x_{0}) $$
	> for every $x_{0}\in\mathbb{R}$.  We have 
	> $$ |x^{2} - x_{0}^{2}| =|(x+x_{0})(x-x_{0})|\leq |x + x_{0}||x-x_{0}| . $$
	> Recall that we must check that $|f(x) - f(x_{0})|< \epsilon$ whenever $|x - x_{0}|<\delta$, with $\delta>0$ to be determined depending on $\epsilon>0$.  A direct computation shows that 
	> $$ | x+ x_{0}| =|x - x_{0} + 2x_{0}|\leq |x - x_{0}| + 2|x_{0}| $$
	> so that 
	> $$ |x^{2} - x_{0}^{2}|\leq (|x - x_{0}| + 2|x_{0}|)\,|x-x_{0}| < (2|x_{0}| + \delta_{\epsilon})\,\delta_{\epsilon}. $$
	> Therefore, if 
	> $$ \delta_{\epsilon}^{2} + 2|x_{0}| \delta_{\epsilon} - \epsilon<0 $$
	> we are done. By solving the previous [quadratic equation](https://en.wikipedia.org/wiki/Quadratic_equation) in the variable $\delta_{\epsilon}$ we obtain the condition 
	> $$ 0 < \delta_{\epsilon} <  \sqrt{x^{2}_{0} + \epsilon} -|x_{0}| = \sqrt{x^{2}_{0} + \epsilon} - \sqrt{x^{2}_{0}}. $$

2)  Using previous results and [[1.2 Limits of scalar functions#^f50bb0|algebraic manipulations of limits]], check that every polynomial function is continuous.

3) Use the [[1.2 Limits of scalar functions#Improper limits|definition]] to check the following limits: 
	$$ \begin{split} 1) \quad & \lim_{x\rightarrow +\infty}\,x^{n}=+\infty \\ & \\ 2) \quad & \lim_{x\rightarrow -\infty}\,x^{2n}=+\infty \\ & \\ 3) \quad & \lim_{x\rightarrow -\infty}\,x^{2n+1}=-\infty \\ & \\ 4) \quad & \lim_{x\rightarrow 0^{\pm}} \;\frac{1}{x^{2n}} =+ \infty \\& \\ 5) \quad & \lim_{x\rightarrow 0^{\pm}} \;\frac{1}{x^{2n+1}} =\pm \infty \\& \\ 	6)   \quad & \lim_{x\rightarrow \pm\infty} \;\frac{1}{x^{n}} =0 \\& \\ \end{split} $$
	>[!note]- Solution 
	>1) We must prove that, for every $K>0$, there is $M>0$ such that $x>M$ implies $f(x)=x^{n}>K$. Recall that $a>b>0$ implies $a^{n}> b^{n}$ for every natural number $n>0$ (can you see why?). Then, taking $M=\sqrt[n]{K}$, we have $f(x)=x^{n}> M^{n}=K$ as requested.
	>2) We must prove that, for every $K>0$, there is $M>0$ such that $x<-M$ implies  $f(x)=x^{2n}>K$. Recall that $a<b<0$ implies $a^{2n}>b^{2n}>0$ for every natural number $n>0$ (can you see why?). Then, taking $M=\sqrt[2n]{K}$, we have $f(x)=x^{2n}>M^{2n}=K$ as requested.
	>3) We must prove that, for every $K>0$, there is $M>0$ such that $x<-M$ implies $f(x)=x^{2n+1}<-K$. Recall that $a<b<0$ implies $a^{2n+1}<b^{2n+1}<0$ for every natural number $n>0$ (can you see why?). Then, taking $M=\sqrt[2n+1]{K}$, we have $f(x)=x^{2n+1}<-M^{2n+1}=-K$ as requested.
	>4) For the right limit ($0^{+}$), we must prove that, for every $K>0$, there is $\delta>0$ such that $0<x<\delta$ implies $f(x)>K$. If $0<x<\delta$, then $\frac{1}{\delta}<\frac{1}{x}$, which means $\frac{1}{\delta^{2n}}<\frac{1}{x^{2n}}$. Taking $\delta=K^{\frac{1}{2n}}$, we have $f(x)=\frac{1}{x^{2n}}>\frac{1}{\delta^{2n}}=K$ as requested. For the left limit ($0^{-}$), we must prove that, for every $K>0$, there is $\delta>0$ such that $|x|<\delta$, with $x<0$, implies $f(x)>K$. Recall that $x^{2n}>0$ even if $x<0$. If $|x|<\delta$, then $\frac{1}{\delta}<\frac{1}{|x|}$, which means $\frac{1}{\delta^{2n}}<\frac{1}{x^{2n}}$. Taking $\delta=K^{\frac{1}{2n}}$, we have $f(x)=\frac{1}{x^{2n}}>\frac{1}{\delta^{2n}}=K$ as requested.
	>5) For the right limit ($0^{+}$), we must prove that, for every $K>0$, there is $\delta>0$ such that $0<x<\delta$ implies $f(x)>K$. If $x<\delta$, then $\frac{1}{\delta}<\frac{1}{x}$, which means $\frac{1}{\delta^{2n+1}}<\frac{1}{x^{2n+1}}$. Taking $\delta=K^{\frac{1}{2n+1}}$, we have $f(x)=\frac{1}{x^{2n+1}}>\frac{1}{\delta^{2n+1}}=K$ as requested. For the left limit ($0^{-}$), we must prove that, for every $K>0$, there is $\delta>0$ such that $|x|<\delta$, with $x<0$, implies $f(x)<-K$, which is equivalent to $|f(x)|>K$. Recall that $x^{2n+1}<0$ when $x<0$. If $|x|<\delta$, then $\frac{1}{\delta}<\frac{1}{|x|}$, which means $\frac{1}{\delta^{2n+1}}<\frac{1}{|x^{2n+1}|}$. Taking $\delta=\frac{1}{\sqrt[2n+1]{K}}$, we have $|f(x)|=\frac{1}{|x^{2n+1}|}>\frac{1}{\delta^{2n+1}}=K$ as requested.
	>6) For $x\rightarrow+\infty$, we must prove that, for every $\epsilon>0$, there is $M>0$ such that $x>M$ implies $|f(x) - 0|<\epsilon$. If $x>M>0$, then $|f(x)|=|\frac{1}{x^{n}}|=\frac{1}{x^{n}}<\frac{1}{M^{n}}$, so that $M>\frac{1}{\sqrt[n]{\epsilon}}$ does the job. For $x\rightarrow-\infty$, we must prove that, for every $\epsilon>0$, there is $M>0$ such that $x<-M$ implies $|f(x)-0|<\epsilon$. If $x<-M<0$ then $|x|>M$ so that $|f(x)|=\frac{1}{|x^{n}|}<\frac{1}{M^{n}}$, and thus $M>\frac{1}{\sqrt[n]{\epsilon}}$ does the job.

4) Consider the function $([0,+\infty),\mathbb{R},f,\mathbb{R})$, where $f(x)=x^{\frac{1}{n}}\equiv\sqrt[n]{x}$ with $n>1$: 
	1) prove it is a continuous function;
	2) find its limit at $+\infty$;
	3) what can we say regarding $f(x)=x^{\frac{m}{n}}$? 
	
	>[!note]- Solution 
	4)  We start noting that $([0,+\infty),\mathbb{R},f,\mathbb{R})$ is the [[1.1 Sets and functions#^ac035a|inverse function]] of $([0,+\infty),\mathbb{R},g,\mathbb{R})$ where $g(y)=y^{n}$.  In exercise 2) above, we proved that $((-\infty,+\infty),\mathbb{R},g,\mathbb{R})$ is continuous. Therefore, $((0,+\infty),\mathbb{R},g,\mathbb{R})$ is continuous, and its inverse function $((0,+\infty),\mathbb{R},f,\mathbb{R})$ is continuous ([[1.2 Limits of scalar functions#^0478fa|see here]]). The continuity of $([0,+\infty),\mathbb{R},f,\mathbb{R})$  at $0$ can be proved applying the [[1.2 Limits of scalar functions#^cbf378|very definition of limit]], and recalling that $0<a<b$ implies $0<a^{\frac{1}{n}}<b^{\frac{1}{n}}$ (can you see why?). 
	5)  Using the previous inequality, we have that $0<\sqrt[n]{M}<\sqrt[n]{x}$, so that $M=K^{n}$ implies $x^{\frac{1}{n}}>K$,  which means that  $\lim_{x\rightarrow+\infty}f(x)=+\infty$. 
	6)  Once we know $([0,+\infty),\mathbb{R},f,\mathbb{R})$ is continuous, we can use the [[1.2 Limits of scalar functions#^47f720|algebra of continuous functions]] to conclude $([0,+\infty),\mathbb{R},h,\mathbb{R})$, where $h(x)=x^{\frac{m}{n}}$, is continuous too.

5) Check the following limits: 
	$$ \begin{split} 1) \quad & \lim_{x\rightarrow 1}\,\frac{x}{x+1}=\frac{1}{2}  \\ & \\ 2) \quad &  \lim_{x\rightarrow 0}\, \frac{x}{|x|}=\nexists \\ & \\ 3) \quad &  \lim_{x\rightarrow 0}\, \frac{|x|}{ x }=\nexists \\ & \\ 4) \quad &  \lim_{x\rightarrow 0}\, f(x) =\nexists \quad \mbox{ with } f(x)= \left\{\begin{matrix} 1-x^{2} & \mbox{ if } x<0 \\ x^{3} & \mbox{ if } x\geq 0\end{matrix}\right.  \\ & \\ 5) \quad &  \lim_{x\rightarrow 1^{\pm}}\, \frac{x^{2}-1}{ x^{2} -2x + 1 }= \pm\infty\\ & \\ 6) \quad &  \lim_{x\rightarrow 2^{+}}\, \frac{\sqrt{x^{2} -4}}{x-2} = +\infty \end{split} $$
	>[!note]- Solution
	7)  Use [[1.2 Limits of scalar functions#^f50bb0|algebraic manipulation of limits]].
	8)  When $x\rightarrow 0^{+}$, it is $\frac{x}{|x|}=1$, while $\frac{x}{|x|}=-1$ when $x\rightarrow 0^{-}$. Consequently, the left and right limits are different, and the limit for $x\rightarrow 0$ does not exist.
	9)  The proof is analogous to that of 2) above. 
	10)  The proof is analogous to that of 2) above.
	11)  When $x=1$, both numerator and denominator vanish, and we get an indeterminate form. However, the fact that both polynomials have a common root ($x=1$) suggests we [factorize them](https://en.wikipedia.org/wiki/Polynomial#Factoring). In particular, we have $x^{2}-1=(x-1)(x+1)$, and $x^{2}-2x +1=(x-1)(x-1)$. Consequently, we have 
	>		$$ \frac{x^{2}-1}{x^{2}-2x+1}=\frac{x+1}{x-1}. $$
	>		Now, the numerator tends to 2 when $x\rightarrow 1^{\pm}$, while the denominator tends to $0$. Therefore, using the [[1.2 Limits of scalar functions#^55a3be|algebraic manipulation of limits]], we obtain that the limit is $+\infty$ when $x\rightarrow 1^{+}$ (because the denominator tends to $0$ from the left), and $-\infty$ when $x\rightarrow 1^{-}$ (because the denominator tends to $0$ from the right).
	12)  When $x=2$, both numerator and denominator vanish, and we get an indeterminate form. Putting the denominator in the square root, and using the difference of two squares identity, we obtain 
	>		$$ \frac{\sqrt{x^{2}-4}}{x-2}=\sqrt{\frac{x+2}{x-2}}. $$
	>		Then, the rest of the proof uses the [[1.2 Limits of scalar functions#^c8052c|limit of composite functions]] (with the outer function equal to the square root function) and a reasoning analogous to that of the previous point. 


# 2 Derivatives 



1) Using its [[1.3 Derivatives of scalar functions#^971f59|very definition]], find the derivative of  $f(x)=x^{3}$ and $f(x)=x^{4}$ for every $x_{0}\in\mathbb{R}$.  **Hint**: Use  [Newton's binomial formula](https://en.wikipedia.org/wiki/Binomial_theorem)
	$$ (a+b)^{n}=\sum\limits_{k=0}^{n}{n\choose k} a^{n-k}b^{k}=\sum\limits_{k=0}^{n}{n\choose k} a^{k}b^{n-k}, $$
		where ${n\choose k}=\frac{n!}{k!(n-k)!}$ is the [binomial coefficient](https://en.wikipedia.org/wiki/Binomial_coefficient) counting the ways of choosing an (unordered) subset of $k$ elements from a fixed set of $n$ elements, to check that $\frac{\mathrm{d}f}{dx}=n\, x^{n-1}$ for $f(x)=x^{n}$ and all $n>0$ in $\mathbb{N}$.

2) Compute the derivative of $([0,+\infty),\mathbb{R},f,\mathbb{R})$, where $f(x)=\sqrt[n]{x}=x^{\frac{1}{n}}$ with $n>1$, at each point.
	 >[!note]- Solution 
	 >A direct computation shows that $([0,+\infty),\mathbb{R},f,\mathbb{R})$ is the inverse function of $([0,+\infty),\mathbb{R},g,\mathbb{R})$ with $g(y)=y^{n}$. The function $([0,+\infty),\mathbb{R},g,\mathbb{R})$ is differentiable for every $y>0$. Therefore, [[1.3 Derivatives of scalar functions#^05d051|we conclude that]] $([0,+\infty),\mathbb{R},f,\mathbb{R})$ is differentiable for each $x>0$, and its derivative reads 
	 >$$ f'(x)=\frac{1}{n} x^{\frac{1-n}{n}}. $$
	 >At $y=0$, we can only compute the right derivative of $([0,+\infty),\mathbb{R},g,\mathbb{R})$ :
	 >$$ \lim_{h\rightarrow 0^{+}} \frac{(0+h)^{\frac{1}{n}}-0}{h} = \lim_{h\rightarrow 0^{+}} h^{\frac{1-n}{n}}=\lim_{h\rightarrow 0^{+}} \frac{1}{h^{\frac{n-1}{n}}} = + \infty,$$
	 > and thus $([0,+\infty),\mathbb{R},f,\mathbb{R})$ has no right derivative at $x=0$.

3) Determine for which $x\in\mathbb{R}$ the function $(\mathbb{R},\mathbb{R},f,\mathbb{R})$ is differentiable in the following cases: 
	$$ \begin{split} 	1) \quad & f(x)= |x - 2| \\ & \\ 2) \quad & f(x)= \sqrt{|x|} \\ & \\ 			3) \quad & f(x)= \left\{\begin{matrix}  x^{2} & \mbox{ if } x\leq 1 \\ 2-x & \mbox{ if } x> 1\end{matrix}\right. \\ & \\ 	4) \quad & f(x)= \left\{\begin{matrix} x^{2} -1 & \mbox{ if } x\leq 2 \\  3 & \mbox{ if } x> 2\end{matrix}\right. \\ & \\ 	5) \quad & f(x)= \left\{\begin{matrix}  4x & \mbox{ if } x<1 \\ 2x +2 & \mbox{ if } x\geq 1\end{matrix}\right. \\ & \\ 	6) \quad & f(x)= \left\{\begin{matrix}  \frac{-x^{2}}{2}  & \mbox{ if } x<3 \\ -3x & \mbox{ if } x\geq 3\end{matrix}\right. \end{split} $$
	>[!note]- Solution
	>1) Given the appearance of the absolute value, we split our function in two pieces: $([2,\infty),\mathbb{R},f_{1},\mathbb{R})$ with $f_{1}(x)=x-2=f(x)$, and $((-\infty,2],\mathbb{R},f,\mathbb{R})$, with $f_{2}(x)=2-x=f(x)$. Since we already know the derivative of constant and linear functions, the [[1.3 Derivatives of scalar functions#^5d20ad|algebraic manipulations of derivatives]] ensure $([2,\infty),\mathbb{R},f_{1},\mathbb{R})$ is differentiable for every $x>2$, and its right derivative at $x=2$ is equal to 1. Proceeding analogously for $((-\infty,2],\mathbb{R},f,\mathbb{R})$, with $f_{2}(x)=2-x=f(x)$, we obtain it is differentiable for every $x<2$, and its left derivative at $x=2$ is $-1$. We thus conclude that $(\mathbb{R},\mathbb{R},f,\mathbb{R})$ is differentiable everywhere except at $x=2$.
	>2) Following the idea used in point 1), we split the function in two pieces: $([0,\infty),\mathbb{R},f_{1},\mathbb{R})$ with $f_{1}(x)=\sqrt{x}=f(x)$, and $((-\infty,0],\mathbb{R},f,\mathbb{R})$, with $f_{2}(x)=\sqrt{-x}=f(x)$. Then, exercise 2.2) above shows the function is differentiable everywhere except at $x=0$.
	>3) Following the idea used in point 1) we conclude the function is differentiable for every $x\neq 1$.
	>4) Following the idea used in point 1) we conclude the function is differentiable for every $x\neq 2$.
	>5) Following the idea used in point 1) we conclude the function is differentiable for every $x\neq 1$.
	>6) Following the idea used in point 1) we conclude the function is differentiable everywhere.

4) Whenever possible, compute the derivatives at all points in the maximal domain of the scalar functions determined by:
	$$ \begin{split} 1) \quad &  f(x)= x^{\frac{m}{n}}  \\  & \\5) \quad &  f(x)= \frac{2x}{1-x}  \\  & \\ 3) \quad &  f(x)=\frac{x}{1-x}\,\frac{2-x}{3+x}  \\  & \\ 4) \quad &  f(x)=\frac{(x^{2} +1)^{3}}{x+3}   \\  & \\ 5) \quad &  f(x)=\sqrt{x^{4} + 3x^{2} -2}  \\  & \\ 6) \quad &  f(x)=\sqrt{\frac{x +2}{x^{2}}}  \\  & \\ 7) \quad &  f(x)=\frac{x}{\sqrt{x+2}}  \\  & \\ 8) \quad &    f(x)=(g(x))^{\frac{m}{n}} \end{split} $$
	>[!note]- Solution
	>1) The maximal domain is $[0,+\infty)$. Using the result of exercise 2.2) above together with the [[1.3 Derivatives of scalar functions#^c87d27|chain rule]], we obtain $f'(x)=\frac{m}{n}x^{\frac{m}{n}-1}$ for every $x>0$, and the right derivative at $x=0$ is $0$ when $m\geq n$, and undefined when $m<n$.
	>2) The maximal domain is $(-\infty,1)\cup (1,+\infty)$. Using the [[1.3 Derivatives of scalar functions#^5d20ad|algebraic manipulation of derivatives]] we obtain $f'(x)=\frac{2}{(1-x)^{2}}.$
	>3) The maximal domain is $(-\infty,-3)\cup(-3,1)\cup(1,+\infty)$. The derivative is then computed using the [[1.3 Derivatives of scalar functions#^5d20ad|algebraic manipulation of derivatives]]. You can check your result [here](https://onsolver.com/ ), or look in the [[Home#Tools to help with exercises|home]] for further suggestions.
	>4) The maximal domain is $(-\infty,-3)\cup(-3,+\infty)$. The derivative is then computed using the [[1.3 Derivatives of scalar functions#^5d20ad|algebraic manipulation of derivatives]]. You can check your result [here](https://onsolver.com/ ), or look in the [[Home#Tools to help with exercises|home]] for further suggestions.
	>5) The maximal domain is the subset on which $x^{4}+3x^{2}-2\geq 0$. The derivative is then computed using the [[1.3 Derivatives of scalar functions#^5d20ad|algebraic manipulation of derivatives]] and the [[1.3 Derivatives of scalar functions#^c87d27|chain rule]]. You can check your result [here](https://onsolver.com/ ), or look in the [[Home#Tools to help with exercises|home]] for further suggestions.
	>6) The maximal domain is $[-2,0)\cup(0,+\infty)$. The right derivative at $x=-2$ does not exist, while the derivative in the other points is computed using the [[1.3 Derivatives of scalar functions#^5d20ad|algebraic manipulation of derivatives]] and the [[1.3 Derivatives of scalar functions#^c87d27|chain rule]]. You can check your result [here](https://onsolver.com/ ), or look in the [[Home#Tools to help with exercises|home]] for further suggestions.
	>7) The maximal domain is $(-2,+\infty)$. The derivative is then computed using the [[1.3 Derivatives of scalar functions#^5d20ad|algebraic manipulation of derivatives]] and the [[1.3 Derivatives of scalar functions#^c87d27|chain rule]]. You can check your result [here](https://onsolver.com/ ), or look in the [[Home#Tools to help with exercises|home]] for further suggestions.
	>8) The maximal domain here is the subset on which $g(x)\geq 0$. Then, we can use the [[1.3 Derivatives of scalar functions#^c87d27|chain rule]] to get 
	>	$$ f'(x)=\frac{m}{n}(g(x))^{\frac{m}{n}-1}\,g'(x) $$
	>	at all those $x$ at which $g$ is differentiable and such that $g(x)>0$.
	>	When $g$ is differentiable but $g(x)=0$, the right derivative is undefined when $m<n$ and equal to $0$ when $m\geq n$. Obviously, at all those points at which $g$ is not differentiable, then $f$ is not differentiable.




# 3 Numerical sequences and series



1) Prove the following limits 
	$$ \begin{split} 1) \quad & \lim_{n\rightarrow+\infty}\, n!= + \infty \\ & \\ 	2) \quad &  \lim_{n\rightarrow+\infty}\,\frac{x^{n}}{n!}=0\quad\mbox{ for }\quad |x|\leq 1    \\ & \\	3) \quad &  \lim_{n\rightarrow +\infty}\,\sqrt[n]{n}=1  \\ & \\ 	4) \quad & \lim_{n\rightarrow + \infty}\, \sqrt[n]{n!} = +\infty  \\ & \\ 	5) \quad & \lim_{n\rightarrow +\infty}\,kx^{k+2}-(k+1)x^{k+1}=\left\{\begin{matrix}0 &\mbox{ if } |x|<1 \\ +\infty & \mbox{ if } x>1 \\ \nexists & \mbox{ if } x<-1\end{matrix}\right.     \end{split} $$
	
	>[!note]- Solution
	>1) Because of the factorial, we can not rely on limits of functions. We must prove that, for every $K>0$, there exists $N\in\mathbb{N}$ such that $a_{n}=n!>K$ for all $n>N$. When $n>1$, it holds $n!=n(n-1)\cdots 1> n$, so that, setting $n=N>K$, we get $a_{n}=n!>n>K$ as desired.
	>2) When $|x|<1$, exploiting a [[1.4 Sequences and series#^157012|previous example]], the result the previous point, and the algebraic manipulations of limits of sequences, the desired result follows. When $x=1$, the sequence $a_{n}=1^n$ has limit $1$. Reasoning as before, the result follows. When $x=-1$,  the sequence $a_{n}=(-1)^n$ has no limit. However, $\vert\frac{(-1)^n}{n!}\vert=\vert \frac{1}{n!}\vert$, and we just poved that 
	>		$$ \lim_{n\rightarrow+\infty}\frac{1}{n!}=0 .$$
	>			Therefore, we may exploit the [[1.4 Sequences and series#^0cefdc|very definition of limit]] and immediately conclude the desired result.
	>3) Set $b_{n}\equiv \sqrt[n]{n} -1>0$, so that $n=(1+b_{n})^{n}$. Recalling [Newton's binomial formula](https://en.wikipedia.org/wiki/Binomial_theorem)
	>		$$ (a+b)^{n}=\sum\limits_{k=0}^{n}{n\choose k} a^{n-k}b^{k}=\sum\limits_{k=0}^{n}{n\choose k} a^{k}b^{n-k} , $$ 
	>		it follows that 
	>		$$ n=(1+b_{n})^{n}=\sum\limits_{k=0}^{n}{n\choose k} 1^{k}b_{n}^{n-k}\,\stackrel{k=n-2}{\geq}\, \frac{n(n-1)}{2!} b_{n}^{2}, $$ 
	>		which means that $0\leq b_{n}\leq\sqrt{\frac{2}{(n-1)}}$. The squeeze theorem for sequences then implies 
	>		$$ \lim_{n\rightarrow+\infty} b_{n}=0\;\Longleftrightarrow\; \lim_{n\rightarrow+\infty} \sqrt[n]{n}-1=0 , $$ 
	>		which proves the desired equality.
	>4) We [[1.4 Sequences and series#^5a7f61|have to prove that]], given $K>0$, there is $N>0$ such that $n>N$ implies $a_{n}=\sqrt[n]{n!}>K$. Being $n>N>0$, we can take $n\geq1$. We first prove that $n!\geq (\sqrt{\frac{n}{2}})^{n}$ when $n\geq1$ At this purpose, we introduce the so-called integer part function $\lfloor x \rfloor$ which takes a real number $x$ and gives back the first integer which is smaller than $x$ (for instance, $\lfloor 1.4 \rfloor=1$ and $\lfloor -3.1 \rfloor=-4$)., so that $\lfloor \frac{n}{2}\rfloor \leq \frac{n}{2}\leq \lfloor \frac{n}{2}\rfloor +1$. Then, we have
	>		$$ n!=1\cdot 2\cdots\lfloor \frac{n}{2}\rfloor \left(\lfloor \frac{n}{2}\rfloor+1\right)\cdots n \geq \left(\frac{n}{2}\right)^{n-\lfloor \frac{n}{2}\rfloor}\geq \left(\frac{n}{2}\right)^{\frac{n}{2}} , $$
	>		which means $n!\geq\left(\sqrt{\frac{n}{2}}\right)^{n}$ as claimed, and thus $\sqrt[n]{n!}\geq\sqrt{\frac{n}{2}}$. Finally, the result follows taking $N>2K^{2}$ so that $n>N>2K^{2}$ implies $\sqrt[n]{n!}>\sqrt{\frac{n}{2}}>K$.
	>5) It is $kx^{k+2}-(k+1)x^{k+1}=x^{k+1}(k(x-1)-1)$. Therefore, when $X>1$ the sequence diverges. When $x<-1$, the series alternates positive and negative values, but this values grow indefinitely, so that the limit of the sequence does not exist. When $|x|<1$,  we need to find a different procedure. We start  considering $0\leq x< 1$, and noting that there is $y>0$ such that $x=(1+y)^{-1}$. Therefore, we can use the binomial formula as above to obtain 
	>		$$ (1+y)^{n}=\sum\limits_{k=0}^{n}{n\choose k} y^{n-k}\;\stackrel{k=n-2}{\geq}\;\frac{n(n-1)}{2!}y^{2} . $$
	>			It is important to note that the condition $y>0$ is necessary to obtain the inequality above. Then, we get $nx^{n}\leq \frac{2x^{2}}{(1-x)^{2}(n-1)}$, and thus the squeeze theorem for sequences implies the desired result. The case $-1<x<0$ is handled as before, but taking an overall minus sign out.

^98a973

2) Compute the value of the truncated geometric series associated with 
	$$ a_{n} = \left\{ \begin{matrix} a_{n}=0 & \mbox{ for } n=0,...,r-1 \\ a_{n} = x^{n} & \mbox{ for } n\geq r . \end{matrix} \right. $$
	>[!note]- Solution
	>The trick is to realize that  
	>$$ \sum_{n=0}^{+\infty}a_{n}=\sum_{n=r}^{+\infty}x^{n}= \sum_{n=0}^{+\infty}x^{n+r} = x^{r}\sum_{n=0}^{+\infty}x^{n}, $$
	>which means that the truncated geometric series is proportional to the [[1.4 Sequences and series#^bf33d9|geometric series]], and thus its convergence, as well as its sum, can be deduced from the geometric series.

3) Determine the behavior of the arithmetic-geometric series defined by $a_{n}=nx^{n}$ (starting at $n=0$ or $n=1$).
	>[!note]- Solution
	>First of all, starting at $n=0$ or $n=1$ is irrelevant for the result. Then, once again, the series diverges when $x=1$ because $S_{k}=\sum_{n=0}^{k}a_{n}=1+2+3+\cdots +(k-1) + k= \frac{k(k+1)}{2}$.	When $k\neq 1$, we have 
	>$$ S_{k} - x S_{k} =(x + 2 x^{2} + 3 x^{3} + \cdots + k x^{k})-(x^{2} + 2 x^{3} + 3 x^{4} + k x^{k+1}) = x + x^{2} + \cdots + x^{k} -kx^{k+1} .$$ 	
	>The positive terms in the right-hand-side from the partial sum of the [[1.4 Sequences and series#^bf33d9|geometric series]] apart from the first term. Therefore, we have	
	>$$ (1-x)S_{k}=\frac{x^{k+1}-1}{x-1} -1 -kx^{k+1}=\frac{x-(k+1)x^{k+1} +kx^{k+2}}{1-x}  \Longrightarrow S_{k}=\frac{x-(k+1)x^{k+1} +kx^{k+2}}{(1-x)^{2}}. $$	
	>Because of exercise 3.1.5), when $x>1$ the sequence of partial sums diverges, when $x<-1$ it does not have a limit, while it converges to $0$ when $|x|<1$. Consequently, the sum of the arithmetic-geometric series is 	
	>$$ \sum\limits_{n=0}^{+\infty}nx^{n}=\frac{x}{(1-x)^{2}} $$
	>when $|x|<1$, while its either unbounded or undefined in the other cases.

4) Prove that, if $a_{n}=u_{n}-u_{n+1}$ for some sequence $\{u_{n}\}_{n\in\mathbb{N}}$ (**telescoping series**), then 
	$$ \sum\limits_{n=1}^{\infty}a_{n}=u_{1}-\lim_{n\rightarrow\infty}u_{n} .$$
	>[!note]- Solution
	>The partial sum of the series determined by $a_{n}$ reads 
	>	$$ S_{k}=\sum\limits_{n=1}^{k}u_{n}-u_{n+1}=u_{1}-u_{k+1}, $$
	>		and the result follows from the [[1.4 Sequences and series#^32251b|very definition]] of the sum of a series.
5) Check the following equalities: 
	$$ \begin{split} 	1) &\qquad  \sum_{n=1}^{+\infty}\,\frac{1}{2n(n+1)}\,=\;\frac{1}{2}\\ & \\ 	2)  &\qquad  \sum_{n=0}^{+\infty}\;\frac{n}{10^{n}} \,=\;\frac{10}{81} \\ & \\ 	3)  &\qquad   \sum_{n=2}^{+\infty}\;\frac{1}{n^{2} -n}\,=\;1 \\ & \\ 	4)  &\qquad  \sum_{n=0}^{+\infty}\;\frac{1}{(n+1)(n+3)} \,=\; \frac{3}{4}\\ & \\ 	5)  &\qquad  \sum_{n=0}^{+\infty}\;\frac{2^{n+3}}{3^{n}}\,=\; 24.\end{split}$$
	>[!note]- Solution
	>1)  The result follows from exercise 3.4) above once we note that $a_{n}=\frac{1}{2}(\frac{1}{n}-\frac{1}{n+1})$.
	>2) This exercise should deserve no explication.
	>3) We note that $a_{n}= \frac{1}{n-1}-\frac{1}{n}$. Then, we perform the replacement $n=k+1$ so that
	>		$$ \sum\limits_{n=2}^{+\infty}a_{n}\rightarrow\sum\limits_{k=1}^{+\infty}a_{k} $$
	>			with $a_{k}=\frac{1}{k}-\frac{1}{k+1}$, and the result follows again from exercise 3.4) above.
	>4) We note that $a_{n}=\frac{1}{2}(\frac{1}{n+1} - \frac{1}{n+3})$, so that the replacement $k=n+1$ gives $a_{k}=\frac{1}{2}(\frac{1}{k} - \frac{1}{k+2})$. Now, we can not directly use the result of exercise 3.4) above, however, we can adapt the proof used there to this case and obtain  
	>		$$ \sum_{k=1}^{\infty}a_{k}=\sum_{k=1}^{+\infty}u_{k}-u_{k+2}=u_{1}+u_{2}+\lim_{k\rightarrow +\infty}u_{k}, $$
	>			 from which the desired result immediately follows.
	>5) As exercise 3.5.2) above, this exercise should deserve no explanation.



# 4 Power series, trascendental functions, and Taylor expansion



1) Compute the derivatives, at all points in the maximal domain at which it makes sense, of the scalar functions determined by:
	$$ \begin{split} 1) \quad &  f(x) =\ln(x-a) \\ & \\ 2) \quad & f(x) =\ln(|x|) \\ & \\ 3) \quad & f(x)= x^{\alpha}   \\ & \\ 4) \quad & f(x) = \arcsin(x) \\ & \\ 	5) \quad & f(x) = \arccos(x) \\ & \\ 	6) \quad & f(x) = \tan(x)  \\ & \\ 	7) \quad & f(x) =\cot(x) \\ & \\ 	8) \quad & f(x) = \arctan(x) \\ & \\ 	9) \quad & f(x) =  x^{x} \\ & \\ 	10) \quad & f(x) = \sqrt{\tan(x)} \\ & \\ 	11) \quad & f(x) = \arctan\left(x^{3} - e^{x^{2}}\right) \\ & \\ 	12) \quad &  f(x)=(g(x))^{h(x)} \\ & \\	13) \quad & f(x)= \arctan\left(\frac{g(x)}{h(x)}\right)  \end{split} $$
	>[!note]- Solution
		> 1) Since $\ln(x-a)$ is the inverse function of $\mathrm{exp}(x-a)=\mathrm{e}^{x-a}$, we can use the [[1.3 Derivatives of scalar functions#^05d051|formula for the derivative of the inverse function]] to obtain $f'(x)=\frac{1}{x-a}$. Alternatively, we can use $g(y)=\ln(y)$,  $y(x)=x-a$, and the [[1.3 Derivatives of scalar functions#^c87d27|chain rule]].
		> 2) Because of the absolute value, we have to split the function for $x>0$ and $x<0$ (note that $x=0$ is forbidden). Once the split is done, we can proceed as in point 1) above. The result is $f'(x)=\frac{1}{x}$.
		> 3) The trick is to write $x^{\alpha}=\mathrm{e}^{\alpha\ln(x)}$ and then apply the [[1.3 Derivatives of scalar functions#^c87d27|chain rule]]. The result is thus $f'(x)=\alpha x^{\alpha-1}$.
		> 4) Recall that the domain of $\arcsin(x)$ is $-1\leq x\leq 1$. Use the [[1.3 Derivatives of scalar functions#^05d051|formula for the derivative of the inverse function]] to obtain $f'(x)=\frac{1}{\cos(\arcsin(x))}$. Since $-\frac{\pi}{2}<\arcsin(x)<\frac{\pi}{2}$ when $-1<x<1$, $\cos(\arcsin(x))>0$, and we can use the fact that $\cos(x)=\sqrt{1-\sin^{2}(x)}$  to obtain $f'(x)=\frac{1}{\sqrt{1-x^{2}}}$.
		> 5) Proceed as in point 4) above to get $f'(x)=-\frac{1}{\sqrt{1-x^{2}}}$.
		> 6) Use the derivative of $\sin(x)$ and $\cos(x)$ together with the [[1.3 Derivatives of scalar functions#^5d20ad|algebraic manipulations of derivatives]] to get $f'(x)=\frac{1}{\cos^{2}(x)}$.
		> 7) Use the derivative of $\sin(x)$ and $\cos(x)$ together with the [[1.3 Derivatives of scalar functions#^5d20ad|algebraic manipulations of derivatives]] to get $f'(x)=-\frac{1}{\sin^{2}(x)}$.
		> 8) Recalling that $\frac{1}{\cos^{2}(x)}=1 + \tan^{2}(x)$, proceed as in point 4) above to get $f'(x)=\frac{1}{1+x^{2}}$.
		> 9) Proceed as in point 3) above to get $f'(x)=x^{x}(\ln(x)+1)$.
		> 10) Use the [[1.3 Derivatives of scalar functions#^c87d27|chain rule]] to get $f'(x)=\frac{1}{2}(\sqrt{\tan(x)}\cos^{2}(x))^{-1}$.
		> 11) Use the [[1.3 Derivatives of scalar functions#^c87d27|chain rule]] to get $f'(x)=\frac{3x^{2} - 2x\mathrm{e}^{x^{2}}}{1+ (x^{3} - \mathrm{e}^{x^{2}})^{2}}$.
		> 12) Proceed as in point 3) above, and use the [[1.3 Derivatives of scalar functions#^c87d27|chain rule]] to get $f'(x)=(g(x))^{h(x)}\left(h(x)\ln(g(x)) + \frac{h(x)g'(x)}{g(x)}\right)$.
		> 13) Use the [[1.3 Derivatives of scalar functions#^c87d27|chain rule]] to get $f'(x)=\frac{g'(x)h(x)-g(x)h'(x)}{g^{2}(x)+h^{2}(x)}$.

2) Check the following limits:
	$$\begin{split} 	1) \quad & \lim_{x\rightarrow 0}\, \frac{\tan(x^{2})+2x}{x+x^{2}}= 2\\ & \\	2) \quad & \lim_{x\rightarrow 0}\,\frac{\mathrm{e}^{x} - x - \cos(x)}{\sin(x^{2})} = 1 \\ & \\	3) \quad & \lim_{x\rightarrow +\infty}\,\left(1 + \frac{1}{x}\right)^{x}= \mathrm{e}  \\ & \\	4) \quad & \lim_{x\rightarrow +\infty}\, \frac{\left(1 + \frac{1}{x}\right)^{x^{2}}}{\mathrm{e}^{x}} = \mathrm{e}^{-\frac{1}{2}}\\ & \\	5) \quad & \lim_{x\rightarrow 0} \frac{\arctan(x) -x}{\sin(x) -x}= 2	\end{split}$$
	>	[!note]- Solution
	>	1) We first write
	>		$$ \frac{\tan(x^{2})+2x}{x+x^{2}}=\frac{\sin(x^{2})}{x(1+x)\cos(x^{2})} + \frac{2}{(1+x)},$$
	>		from which it is clear that the second term in the right-hand-side will not give us problems. Then, we note that
	>		$$\frac{\sin(x^{2})}{x(1+x)\cos(x^{2})}=\frac{x\sin(x^{2})}{x^{2}(1+x)\cos(x^{2})},$$
	>		so that we can use the limit
	>		$$ \lim_{y\rightarrow 0}\frac{\sin(y)}{y}=1$$
	>		together with the [[1.2 Limits of scalar functions#^c8052c|compostion of limits]] to verify the claimed result.
	>	2) Since the first order expansion of $\sin(x^{2})$ already contain $x^{2}$, we expand $\mathrm{e}^{x}$ and $\cos(x)$ up to the second order. Then, the result follows from a direct computation taking into account [[1.5 Power series, trascendental functions, and Taylor series#^113a5b|the property of remainder]].
	>	3) Since the limit is for $x\rightarrow+\infty$, we can not use Taylor's theorem. Analogously, we can not apply L'Hôpital's rule because we do not have a quotient of functions. However, we can exploit a trick. We start writing $(1+\frac{1}{x})^{x}=\mathrm{e}^{x\ln(1+\frac{1}{x})}$. Then, we introduce the auxiliary variable $y=(1+\frac{1}{x})$, so that $x=\frac{1}{y-1}$, and thus $(1+\frac{1}{x})^{x}=\mathrm{e}^{\frac{\ln(y)}{y-1}}$. Moreover, we have $y\rightarrow 1^{+}$ when $x\rightarrow+\infty$, so that
	>		$$ \lim_{x\rightarrow +\infty} \,(1+\frac{1}{x})^{x}= \mathrm{e}^{\lim_{y\rightarrow 1^{+}}\,\frac{\ln(y)}{y-1}}, $$
	>			where we applied the [[1.2 Limits of scalar functions#^c8052c|limit of composite functions]] to obtain the last equality. We can now apply L'Hôpital's and verify the limit. 
	>	4) To verify the limit, we follow the steps in point 3) to obtain
	>		$$ \frac{\left(1 + \frac{1}{x}\right)^{x^{2}}}{\mathrm{e}^{x}} =\mathrm{e}^{\frac{\ln(y)}{(y-1)^{2}} - \frac{1}{y-1}} .$$
	>		Then, we use [[1.5 Power series, trascendental functions, and Taylor series|Taylor's expansion]] for $\ln(y)$ around $y_{0}=1$, and the limit follows.
	>	5) To verify the limit, it suffices to use [[1.5 Power series, trascendental functions, and Taylor series|Taylor's expansion]].

3) Use Taylor's theorem to estimate:
	1) $\mathrm{e}^{0.2}$ with an error smaller than $0.0005$;
	2) $\sin(0.1)$ with an error smaller than $0.0005$.
	
	>[!note]- Solution 
	>3) The exponential function [[1.5 Power series, trascendental functions, and Taylor series#^113a5b|can be written as]]
	>		$$ \mathrm{e}^{x}=\sum\limits_{k=0}^{+\infty} \frac{x^{k}}{k!}=1 + x + \frac{x}{2!} + \cdots \frac{x^{n}}{n!} + o(x^{n+1}),$$
	>		where the remainder is
	>		$$ o(x^{n+1})=\frac{\mathrm{e}^{\theta x}}{(n+1)!}x^{n+1} $$
	>		with $\theta\in(0,1)$.
	>		In particular, we have $x=0.2$, and we want the remainder to be smaller than $0.0005$. Therefore, we obtain the chain of inequalities
	>		$$|o(0.2^{n+1})|=\left|\frac{\mathrm{e}^{\theta 0.2}}{(n+1)!}0.2^{n+1}\right|<\left|\frac{3}{(n+1)!}0.2^{n+1}\right|<0.00005,$$
	>		which means $5^{n+1}(n+1)!>6000$. The least value of $n$ satisfying the inequality is $n=3$, and we have
	>		$$\mathrm{e}^{0.2} \approx 1+ 0.2 + \frac{(0.2)^{2}}{2} + \frac{(0.2)^{3}}{6}.$$
	>4) The _sine_ function [[1.5 Power series, trascendental functions, and Taylor series#^113a5b|can be written as]]
	>		$$ \sin(x)=\sum_{k=0}^{+\infty} \frac{(-1)^{k}x^{2k+1}}{(2k+1)!}=x - \frac{x^{3}}{3!} + \cdots \frac{(-1)^{n} x^{2n+1}}{(2n+1)!} + o(x^{2(n+1)+1}),$$
	>		where the remainder is
	>		$$ o(x^{2(n+1)+1})=\frac{\sin^{(n+1)}(\theta x)}{(2(n+1)+1)!}x^{2(n+1)+1} $$
	>		with $\theta\in(0,1)$. 
	>		In particular, we have $x=0.1$, and we want the remainder to be smaller than $0.0005$. Therefore, we obtain the chain of inequalities
	>		$$|o(0.1^{2(n+1)+1})|=\left|\frac{\sin^{(n+1)}(\theta 0.2)}{(2(n+1)+1)!}0.1^{2(n+1)+1}\right|\leq\left|\frac{1}{(2(n+1)+1)!}0.1^{2(n+1)+1}\right|<0.00005,$$
	>		which means $10^{2(n+1)+1}(2(n+1)+1)!>2000$. The least integer satisfying the inequality is $n=0$.



# 5 Global extrema of scalar functions

1) Study the global extrema of the following functions:
	$$	\begin{split}	1) \quad & f(x)\,=\; x + \frac{1}{x} \\ & \\	2) \quad & f(x)\,=\; \frac{x^{2}}{1+x} \\ & \\	3) \quad & f(x)\,=\;  x^{2}\,\left(2+x\right)^{\frac{1}{3}}\\ & \\	4) \quad & f(x)\,=\; |x - 3| + |2x + 1|  \\ & \\	5) \quad & f(x)\,=\;  x + \cos(2x) \\ & \\	6) \quad & f(x)\,=\;  \left\{\begin{matrix} 2 - 2x -x^{2} & \quad -2\leq x\leq 0 \\ |x-2| & \quad  0<x<3 \\ \frac{1}{3}\left(x-2\right)^{2} & \quad  3\leq x \leq 4 \end{matrix}\right.\\ & \\	7) \quad & f(x)\,=\; \left\{\begin{matrix} x^{2} +1 & \quad  -2\leq x < 1 \\ 5 + 2x -x^{2}& \quad  -1\leq x\leq 3 \\ x-1 & \quad  3< x < 6 \end{matrix}\right.  \\ & \\	8) \quad & f(x)\,=\;  \left\{\begin{matrix} \frac{3-x^{2}}{2} & \quad  x < -1 \\ \frac{1}{x} & \quad  -1\leq x \neq 0    \end{matrix}\right.\\ & \\	9) \quad & f(x)\,=\; 1 - (x-1)^{\frac{1}{3}} \\ & \\	10) \quad & f(x)\,=\; \sqrt{x} - \frac{1}{\sqrt{x}} \\ & \\	\end{split}	$$
	
	>[!note]- Solution
	>1) The maximal domain of the function is $D=\mathbb{R}-\{0\}$. The function is smooth (in particular, continuous) in $D$ because it is the sum of two smooth functions in $D$. The behavior at $0$ is determined uniquely by $\frac{1}{x}$, which we know goes to $\pm\infty$ when $x\rightarrow0^{\pm}$ because of previous exercises.  The limits for $x\rightarrow\pm\infty$ are determined by the piece $g(x)=x$, and we know they are $\pm\infty$ because of previous exercises. From this, we already conclude that there will be no global extrema. Concerning local extrema, we compute the derivative and look for critical points
	>		$$ f'(x)= 1 -\frac{2}{x^{2}}\;\Longrightarrow\; f'(x)=0 \;\Longrightarrow x^{2}=2\;\Longrightarrow x=\pm\sqrt{2}.$$
	>		There are no other critical points because the derivative exists at each point in the maximal domain of the function. The condition $f'(x)>0$ implies $x^2>2$, and thus we see that $x=\sqrt{2}$ is a local minimum, while $x=-\sqrt{2}$ is a local maximum.
	>	2) The maximal domain of the function is $D=\mathbb{R}-\{-1\}$, and the function is smooth in $D$ because it is the quotient of two smooth functions in $D$. Remembering the [[1.2 Limits of scalar functions#^c8052c|limit of composite functions]] and what previous exercises taught us about $g(t)=\frac{1}{t}$ when $t\rightarrow 0^{\pm}$, we conclude $f(x)$ tends to $\pm\infty$ when $x\rightarrow -1^{\pm}$. Then, we have
	>		$$ \lim_{x\rightarrow\pm\infty}\frac{x^{2}}{x+1}=\lim_{x\rightarrow\pm\infty}\frac{x^{2}}{x\left(1+\frac{1}{x}\right)}=\pm\infty .$$
	>		We thus conclude that there will be no global extrema for the function. Concerning local extrema, we have
	>		$$f'(x)=\frac{x(2 + x)}{(1+x)^{2}}\;\Longrightarrow\;f'(x)\geq 0\;\Longrightarrow x\geq 0,\;x\leq -2 . $$
	>		Consequently, $x=-2$ is a local maximum, while $x=0$ is a local minimum.
	>	